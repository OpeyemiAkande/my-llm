{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21903669",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_Number' from 'torch.types' (c:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\__init__.py:2169\u001b[39m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2160\u001b[39m \n\u001b[32m   2161\u001b[39m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2163\u001b[39m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[32m   2164\u001b[39m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[32m   2165\u001b[39m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[32m   2166\u001b[39m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[32m   2167\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2169\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m   2170\u001b[39m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[32m   2171\u001b[39m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[32m   2172\u001b[39m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[32m   2173\u001b[39m     accelerator \u001b[38;5;28;01mas\u001b[39;00m accelerator,\n\u001b[32m   2174\u001b[39m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[32m   2175\u001b[39m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[32m   2176\u001b[39m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[32m   2177\u001b[39m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[32m   2178\u001b[39m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[32m   2179\u001b[39m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[32m   2180\u001b[39m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[32m   2181\u001b[39m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[32m   2182\u001b[39m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[32m   2183\u001b[39m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[32m   2184\u001b[39m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[32m   2185\u001b[39m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[32m   2186\u001b[39m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[32m   2187\u001b[39m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[32m   2188\u001b[39m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[32m   2189\u001b[39m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[32m   2190\u001b[39m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[32m   2191\u001b[39m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[32m   2192\u001b[39m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[32m   2193\u001b[39m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[32m   2194\u001b[39m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[32m   2195\u001b[39m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[32m   2196\u001b[39m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[32m   2197\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m   2198\u001b[39m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[32m   2199\u001b[39m )\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[32m   2203\u001b[39m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[32m   2204\u001b[39m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\__init__.py:74\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe ``distributions`` package contains parameterizable probability distributions\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mand sampling functions. This allows the construction of stochastic computation\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \u001b[33;03m    loss.backward()\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbernoulli\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bernoulli\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Beta\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\transforms.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constraints\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _sum_rightmost,\n\u001b[32m     13\u001b[39m     broadcast_all,\n\u001b[32m     14\u001b[39m     lazy_property,\n\u001b[32m     15\u001b[39m     tril_matrix_to_vec,\n\u001b[32m     16\u001b[39m     vec_to_tril_matrix,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad, softplus\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Number\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\utils.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_tensor_like\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Number\n\u001b[32m     13\u001b[39m euler_constant = \u001b[32m0.57721566490153286060\u001b[39m  \u001b[38;5;66;03m# Euler Mascheroni Constant\u001b[39;00m\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbroadcast_all\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogits_to_probs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvec_to_tril_matrix\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m ]\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_Number' from 'torch.types' (c:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\types.py)"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08947a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  raw_text = f.read()\n",
    "\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5d1839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a24cca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840d9421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'a', 'this', '--', 'a', 'test?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is a this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74e6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998edbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--', 'that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing', '--', 'his', 'last', 'Chicago', 'sitter', '--', 'deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course', 'it', \"'\", 's', 'going', 'to', 'send', 'the', 'value', 'of', 'my', 'picture', \"'\", 'way', 'up', ';', 'but', 'I', 'don', \"'\", 't', 'think', 'of', 'that', ',', 'Mr', '.', 'Rickham', '--', 'the', 'loss', 'to', 'Arrt', 'is', 'all', 'I', 'think', 'of', '.', '\"', 'The', 'word', ',', 'on', 'Mrs', '.', 'Thwing', \"'\", 's', 'lips', ',', 'multiplied', 'its', '_', 'rs', '_', 'as', 'though', 'they', 'were', 'reflected', 'in', 'an', 'endless', 'vista', 'of', 'mirrors', '.', 'And', 'it', 'was', 'not', 'only', 'the', 'Mrs', '.', 'Thwings', 'who', 'mourned', '.', 'Had', 'not', 'the', 'exquisite', 'Hermia', 'Croft', ',', 'at', 'the', 'last', 'Grafton', 'Gallery', 'show', ',', 'stopped', 'me', 'before', 'Gisburn', \"'\", 's', '\"', 'Moon-dancers', '\"', 'to', 'say', ',', 'with', 'tears', 'in', 'her', 'eyes', ':', '\"', 'We', 'shall', 'not', 'look', 'upon', 'its', 'like', 'again', '\"', '?', 'Well', '!', '--', 'even', 'through', 'the', 'prism', 'of', 'Hermia', \"'\", 's', 'tears', 'I', 'felt', 'able', 'to', 'face', 'the', 'fact', 'with', 'equanimity', '.', 'Poor', 'Jack', 'Gisburn', '!', 'The', 'women', 'had', 'made', 'him', '--', 'it', 'was', 'fitting', 'that', 'they', 'should', 'mourn', 'him', '.', 'Among', 'his', 'own', 'sex', 'fewer', 'regrets', 'were', 'heard', ',', 'and', 'in', 'his', 'own', 'trade', 'hardly', 'a', 'murmur', '.', 'Professional', 'jealousy', '?', 'Perhaps', '.', 'If', 'it', 'were', ',', 'the', 'honour', 'of', 'the', 'craft', 'was', 'vindicated', 'by', 'little', 'Claude', 'Nutley', ',', 'who', ',', 'in', 'all', 'good', 'faith', ',', 'brought', 'out', 'in', 'the', 'Burlington', 'a', 'very', 'handsome', '\"', 'obituary', '\"', 'on', 'Jack', '--', 'one', 'of', 'those', 'showy', 'articles', 'stocked', 'with', 'random', 'technicalities', 'that', 'I', 'have', 'heard', '(', 'I', 'won', \"'\", 't', 'say', 'by', 'whom', ')', 'compared', 'to', 'Gisburn', \"'\", 's', 'painting', '.', 'And', 'so', '--', 'his', 'resolve', 'being', 'apparently', 'irrevocable', '--', 'the', 'discussion', 'gradually', 'died', 'out', ',', 'and', ',', 'as', 'Mrs', '.', 'Thwing', 'had', 'predicted', ',', 'the', 'price', 'of', '\"', 'Gisburns', '\"', 'went', 'up', '.', 'It', 'was', 'not', 'till', 'three', 'years', 'later', 'that', ',', 'in', 'the', 'course', 'of', 'a', 'few', 'weeks', \"'\", 'idling', 'on', 'the', 'Riviera', ',', 'it', 'suddenly', 'occurred', 'to', 'me', 'to', 'wonder', 'why', 'Gisburn', 'had', 'given', 'up', 'his', 'painting', '.', 'On', 'reflection', ',', 'it', 'really', 'was', 'a', 'tempting', 'problem', '.', 'To', 'accuse', 'his', 'wife', 'would', 'have', 'been', 'too', 'easy', '--', 'his', 'fair', 'sitters', 'had', 'been', 'denied', 'the', 'solace', 'of', 'saying', 'that', 'Mrs', '.', 'Gisburn', 'had', '\"', 'dragged', 'him', 'down', '.', '\"', 'For', 'Mrs', '.', 'Gisburn', '--', 'as', 'such', '--', 'had', 'not', 'existed', 'till', 'nearly', 'a', 'year', 'after', 'Jack', \"'\", 's', 'resolve', 'had', 'been', 'taken', '.', 'It', 'might', 'be', 'that', 'he', 'had', 'married', 'her', '--', 'since', 'he', 'liked', 'his', 'ease', '--', 'because', 'he', 'didn', \"'\", 't', 'want', 'to', 'go', 'on', 'painting', ';', 'but', 'it', 'would', 'have', 'been', 'hard', 'to', 'prove', 'that', 'he', 'had', 'given', 'up', 'his', 'painting', 'because', 'he', 'had', 'married', 'her', '.', 'Of', 'course', ',', 'if', 'she', 'had', 'not', 'dragged', 'him', 'down', ',', 'she', 'had', 'equally', ',', 'as', 'Miss', 'Croft', 'contended', ',', 'failed', 'to', '\"', 'lift', 'him', 'up', '\"', '--', 'she', 'had', 'not', 'led', 'him', 'back', 'to', 'the', 'easel', '.', 'To', 'put', 'the', 'brush', 'into', 'his', 'hand', 'again', '--', 'what', 'a', 'vocation', 'for', 'a', 'wife', '!', 'But', 'Mrs', '.', 'Gisburn', 'appeared', 'to', 'have', 'disdained', 'it', '--', 'and', 'I', 'felt', 'it', 'might', 'be', 'interesting', 'to', 'find', 'out', 'why', '.', 'The', 'desultory', 'life', 'of', 'the', 'Riviera', 'lends', 'itself', 'to', 'such', 'purely', 'academic', 'speculations', ';', 'and', 'having', ',', 'on', 'my', 'way', 'to', 'Monte', 'Carlo', ',', 'caught', 'a', 'glimpse', 'of', 'Jack', \"'\", 's', 'balustraded', 'terraces', 'between', 'the', 'pines', ',', 'I', 'had', 'myself', 'borne', 'thither', 'the', 'next', 'day', '.', 'I', 'found', 'the', 'couple', 'at', 'tea', 'beneath', 'their', 'palm-trees', ';', 'and', 'Mrs', '.', 'Gisburn', \"'\", 's', 'welcome', 'was', 'so', 'genial', 'that', ',', 'in', 'the', 'ensuing', 'weeks', ',', 'I', 'claimed', 'it', 'frequently', '.', 'It', 'was', 'not', 'that', 'my', 'hostess', 'was', '\"', 'interesting', '\"', ':', 'on', 'that', 'point', 'I', 'could', 'have', 'given', 'Miss', 'Croft', 'the', 'fullest', 'reassurance', '.', 'It', 'was', 'just', 'because', 'she', 'was', '_', 'not', '_', 'interesting', '--', 'if', 'I', 'may', 'be', 'pardoned', 'the', 'bull', '--', 'that', 'I', 'found', 'her', 'so', '.', 'For', 'Jack', ',', 'all', 'his', 'life', ',', 'had', 'been', 'surrounded', 'by', 'interesting', 'women', ':', 'they', 'had', 'fostered', 'his', 'art', ',', 'it', 'had', 'been', 'reared', 'in', 'the', 'hot-house', 'of', 'their', 'adulation', '.', 'And', 'it', 'was', 'therefore', 'instructive', 'to', 'note', 'what', 'effect', 'the', '\"', 'deadening', 'atmosphere', 'of', 'mediocrity', '\"', '(', 'I', 'quote', 'Miss', 'Croft', ')', 'was', 'having', 'on', 'him', '.', 'I', 'have', 'mentioned', 'that', 'Mrs', '.', 'Gisburn', 'was', 'rich', ';', 'and', 'it', 'was', 'immediately', 'perceptible', 'that', 'her', 'husband', 'was', 'extracting', 'from', 'this', 'circumstance', 'a', 'delicate', 'but', 'substantial', 'satisfaction', '.', 'It', 'is', ',', 'as', 'a', 'rule', ',', 'the', 'people', 'who', 'scorn', 'money', 'who', 'get', 'most', 'out', 'of', 'it', ';', 'and', 'Jack', \"'\", 's', 'elegant', 'disdain', 'of', 'his', 'wife', \"'\", 's', 'big', 'balance', 'enabled', 'him', ',', 'with', 'an', 'appearance', 'of', 'perfect', 'good-breeding', ',', 'to', 'transmute', 'it', 'into', 'objects', 'of', 'art', 'and', 'luxury', '.', 'To', 'the', 'latter', ',', 'I', 'must', 'add', ',', 'he', 'remained', 'relatively', 'indifferent', ';', 'but', 'he', 'was', 'buying', 'Renaissance', 'bronzes', 'and', 'eighteenth-century', 'pictures', 'with', 'a', 'discrimination', 'that', 'bespoke', 'the', 'amplest', 'resources', '.', '\"', 'Money', \"'\", 's', 'only', 'excuse', 'is', 'to', 'put', 'beauty', 'into', 'circulation', ',', '\"', 'was', 'one', 'of', 'the', 'axioms', 'he', 'laid', 'down', 'across', 'the', 'Sevres', 'and', 'silver', 'of', 'an', 'exquisitely', 'appointed', 'luncheon-table', ',', 'when', ',', 'on', 'a', 'later', 'day', ',', 'I', 'had', 'again', 'run', 'over', 'from', 'Monte', 'Carlo', ';', 'and', 'Mrs', '.', 'Gisburn', ',', 'beaming', 'on', 'him', ',', 'added', 'for', 'my', 'enlightenment', ':', '\"', 'Jack', 'is', 'so', 'morbidly', 'sensitive', 'to', 'every', 'form', 'of', 'beauty', '.', '\"', 'Poor', 'Jack', '!', 'It', 'had', 'always', 'been', 'his', 'fate', 'to', 'have', 'women', 'say', 'such', 'things', 'of', 'him', ':', 'the', 'fact', 'should', 'be', 'set', 'down', 'in', 'extenuation', '.', 'What', 'struck', 'me', 'now', 'was', 'that', ',', 'for', 'the', 'first', 'time', ',', 'he', 'resented', 'the', 'tone', '.', 'I', 'had', 'seen', 'him', ',', 'so', 'often', ',', 'basking', 'under', 'similar', 'tributes', '--', 'was', 'it', 'the', 'conjugal', 'note', 'that', 'robbed', 'them', 'of', 'their', 'savour', '?', 'No', '--', 'for', ',', 'oddly', 'enough', ',', 'it', 'became', 'apparent', 'that', 'he', 'was', 'fond', 'of', 'Mrs', '.', 'Gisburn', '--', 'fond', 'enough', 'not', 'to', 'see', 'her', 'absurdity', '.', 'It', 'was', 'his', 'own', 'absurdity', 'he', 'seemed', 'to', 'be', 'wincing', 'under', '--', 'his', 'own', 'attitude', 'as', 'an', 'object', 'for', 'garlands', 'and', 'incense', '.', '\"', 'My', 'dear', ',', 'since', 'I', \"'\", 've', 'chucked', 'painting', 'people', 'don', \"'\", 't', 'say', 'that', 'stuff', 'about', 'me', '--', 'they', 'say', 'it', 'about', 'Victor', 'Grindle', ',', '\"', 'was', 'his', 'only', 'protest', ',', 'as', 'he', 'rose', 'from', 'the', 'table', 'and', 'strolled', 'out', 'onto', 'the', 'sunlit', 'terrace', '.', 'I', 'glanced', 'after', 'him', ',', 'struck', 'by', 'his', 'last', 'word', '.', 'Victor', 'Grindle', 'was', ',', 'in', 'fact', ',', 'becoming', 'the', 'man', 'of', 'the', 'moment', '--', 'as', 'Jack', 'himself', ',', 'one', 'might', 'put', 'it', ',', 'had', 'been', 'the', 'man', 'of', 'the', 'hour', '.', 'The', 'younger', 'artist', 'was', 'said', 'to', 'have', 'formed', 'himself', 'at', 'my', 'friend', \"'\", 's', 'feet', ',', 'and', 'I', 'wondered', 'if', 'a', 'tinge', 'of', 'jealousy', 'underlay', 'the', 'latter', \"'\", 's', 'mysterious', 'abdication', '.', 'But', 'no', '--', 'for', 'it', 'was', 'not', 'till', 'after', 'that', 'event', 'that', 'the', '_', 'rose', 'Dubarry', '_', 'drawing-rooms', 'had', 'begun', 'to', 'display', 'their', '\"', 'Grindles', '.', '\"', 'I', 'turned', 'to', 'Mrs', '.', 'Gisburn', ',', 'who', 'had', 'lingered', 'to', 'give', 'a', 'lump', 'of', 'sugar', 'to', 'her', 'spaniel', 'in', 'the', 'dining-room', '.', '\"', 'Why', '_', 'has', '_', 'he', 'chucked', 'painting', '?', '\"', 'I', 'asked', 'abruptly', '.', 'She', 'raised', 'her', 'eyebrows', 'with', 'a', 'hint', 'of', 'good-humoured', 'surprise', '.', '\"', 'Oh', ',', 'he', 'doesn', \"'\", 't', '_', 'have', '_', 'to', 'now', ',', 'you', 'know', ';', 'and', 'I', 'want', 'him', 'to', 'enjoy', 'himself', ',', '\"', 'she', 'said', 'quite', 'simply', '.', 'I', 'looked', 'about', 'the', 'spacious', 'white-panelled', 'room', ',', 'with', 'its', '_', 'famille-verte', '_', 'vases', 'repeating', 'the', 'tones', 'of', 'the', 'pale', 'damask', 'curtains', ',', 'and', 'its', 'eighteenth-century', 'pastels', 'in', 'delicate', 'faded', 'frames', '.', '\"', 'Has', 'he', 'chucked', 'his', 'pictures', 'too', '?', 'I', 'haven', \"'\", 't', 'seen', 'a', 'single', 'one', 'in', 'the', 'house', '.', '\"', 'A', 'slight', 'shade', 'of', 'constraint', 'crossed', 'Mrs', '.', 'Gisburn', \"'\", 's', 'open', 'countenance', '.', '\"', 'It', \"'\", 's', 'his', 'ridiculous', 'modesty', ',', 'you', 'know', '.', 'He', 'says', 'they', \"'\", 're', 'not', 'fit', 'to', 'have', 'about', ';', 'he', \"'\", 's', 'sent', 'them', 'all', 'away', 'except', 'one', '--', 'my', 'portrait', '--', 'and', 'that', 'I', 'have', 'to', 'keep', 'upstairs', '.', '\"', 'His', 'ridiculous', 'modesty', '--', 'Jack', \"'\", 's', 'modesty', 'about', 'his', 'pictures', '?', 'My', 'curiosity', 'was', 'growing', 'like', 'the', 'bean-stalk', '.', 'I', 'said', 'persuasively', 'to', 'my', 'hostess', ':', '\"', 'I', 'must', 'really', 'see', 'your', 'portrait', ',', 'you', 'know', '.', '\"', 'She', 'glanced', 'out', 'almost', 'timorously', 'at', 'the', 'terrace', 'where', 'her', 'husband', ',', 'lounging', 'in', 'a', 'hooded', 'chair', ',', 'had', 'lit', 'a', 'cigar', 'and', 'drawn', 'the', 'Russian', 'deerhound', \"'\", 's', 'head', 'between', 'his', 'knees', '.', '\"', 'Well', ',', 'come', 'while', 'he', \"'\", 's', 'not', 'looking', ',', '\"', 'she', 'said', ',', 'with', 'a', 'laugh', 'that', 'tried', 'to', 'hide', 'her', 'nervousness', ';', 'and', 'I', 'followed', 'her', 'between', 'the', 'marble', 'Emperors', 'of', 'the', 'hall', ',', 'and', 'up', 'the', 'wide', 'stairs', 'with', 'terra-cotta', 'nymphs', 'poised', 'among', 'flowers', 'at', 'each', 'landing', '.', 'In', 'the', 'dimmest', 'corner', 'of', 'her', 'boudoir', ',', 'amid', 'a', 'profusion', 'of', 'delicate', 'and', 'distinguished', 'objects', ',', 'hung', 'one', 'of', 'the', 'familiar', 'oval', 'canvases', ',', 'in', 'the', 'inevitable', 'garlanded', 'frame', '.', 'The', 'mere', 'outline', 'of', 'the', 'frame', 'called', 'up', 'all', 'Gisburn', \"'\", 's', 'past', '!', 'Mrs', '.', 'Gisburn', 'drew', 'back', 'the', 'window-curtains', ',', 'moved', 'aside', 'a', '_', 'jardiniere', '_', 'full', 'of', 'pink', 'azaleas', ',', 'pushed', 'an', 'arm-chair', 'away', ',', 'and', 'said', ':', '\"', 'If', 'you', 'stand', 'here', 'you', 'can', 'just', 'manage', 'to', 'see', 'it', '.', 'I', 'had', 'it', 'over', 'the', 'mantel-piece', ',', 'but', 'he', 'wouldn', \"'\", 't', 'let', 'it', 'stay', '.', '\"', 'Yes', '--', 'I', 'could', 'just', 'manage', 'to', 'see', 'it', '--', 'the', 'first', 'portrait', 'of', 'Jack', \"'\", 's', 'I', 'had', 'ever', 'had', 'to', 'strain', 'my', 'eyes', 'over', '!', 'Usually', 'they', 'had', 'the', 'place', 'of', 'honour', '--', 'say', 'the', 'central', 'panel', 'in', 'a', 'pale', 'yellow', 'or', '_', 'rose', 'Dubarry', '_', 'drawing-room', ',', 'or', 'a', 'monumental', 'easel', 'placed', 'so', 'that', 'it', 'took', 'the', 'light', 'through', 'curtains', 'of', 'old', 'Venetian', 'point', '.', 'The', 'more', 'modest', 'place', 'became', 'the', 'picture', 'better', ';', 'yet', ',', 'as', 'my', 'eyes', 'grew', 'accustomed', 'to', 'the', 'half-light', ',', 'all', 'the', 'characteristic', 'qualities', 'came', 'out', '--', 'all', 'the', 'hesitations', 'disguised', 'as', 'audacities', ',', 'the', 'tricks', 'of', 'prestidigitation', 'by', 'which', ',', 'with', 'such', 'consummate', 'skill', ',', 'he', 'managed', 'to', 'divert', 'attention', 'from', 'the', 'real', 'business', 'of', 'the', 'picture', 'to', 'some', 'pretty', 'irrelevance', 'of', 'detail', '.', 'Mrs', '.', 'Gisburn', ',', 'presenting', 'a', 'neutral', 'surface', 'to', 'work', 'on', '--', 'forming', ',', 'as', 'it', 'were', ',', 'so', 'inevitably', 'the', 'background', 'of', 'her', 'own', 'picture', '--', 'had', 'lent', 'herself', 'in', 'an', 'unusual', 'degree', 'to', 'the', 'display', 'of', 'this', 'false', 'virtuosity', '.', 'The', 'picture', 'was', 'one', 'of', 'Jack', \"'\", 's', '\"', 'strongest', ',', '\"', 'as', 'his', 'admirers', 'would', 'have', 'put', 'it', '--', 'it', 'represented', ',', 'on', 'his', 'part', ',', 'a', 'swelling', 'of', 'muscles', ',', 'a', 'congesting', 'of', 'veins', ',', 'a', 'balancing', ',', 'straddling', 'and', 'straining', ',', 'that', 'reminded', 'one', 'of', 'the', 'circus-clown', \"'\", 's', 'ironic', 'efforts', 'to', 'lift', 'a', 'feather', '.', 'It', 'met', ',', 'in', 'short', ',', 'at', 'every', 'point', 'the', 'demand', 'of', 'lovely', 'woman', 'to', 'be', 'painted', '\"', 'strongly', '\"', 'because', 'she', 'was', 'tired', 'of', 'being', 'painted', '\"', 'sweetly', '\"', '--', 'and', 'yet', 'not', 'to', 'lose', 'an', 'atom', 'of', 'the', 'sweetness', '.', '\"', 'It', \"'\", 's', 'the', 'last', 'he', 'painted', ',', 'you', 'know', ',', '\"', 'Mrs', '.', 'Gisburn', 'said', 'with', 'pardonable', 'pride', '.', '\"', 'The', 'last', 'but', 'one', ',', '\"', 'she', 'corrected', 'herself', '--', '\"', 'but', 'the', 'other', 'doesn', \"'\", 't', 'count', ',', 'because', 'he', 'destroyed', 'it', '.', '\"', '\"', 'Destroyed', 'it', '?', '\"', 'I', 'was', 'about', 'to', 'follow', 'up', 'this', 'clue', 'when', 'I', 'heard', 'a', 'footstep', 'and', 'saw', 'Jack', 'himself', 'on', 'the', 'threshold', '.', 'As', 'he', 'stood', 'there', ',', 'his', 'hands', 'in', 'the', 'pockets', 'of', 'his', 'velveteen', 'coat', ',', 'the', 'thin', 'brown', 'waves', 'of', 'hair', 'pushed', 'back', 'from', 'his', 'white', 'forehead', ',', 'his', 'lean', 'sunburnt', 'cheeks', 'furrowed', 'by', 'a', 'smile', 'that', 'lifted', 'the', 'tips', 'of', 'a', 'self-confident', 'moustache', ',', 'I', 'felt', 'to', 'what', 'a', 'degree', 'he', 'had', 'the', 'same', 'quality', 'as', 'his', 'pictures', '--', 'the', 'quality', 'of', 'looking', 'cleverer', 'than', 'he', 'was', '.', 'His', 'wife', 'glanced', 'at', 'him', 'deprecatingly', ',', 'but', 'his', 'eyes', 'travelled', 'past', 'her', 'to', 'the', 'portrait', '.', '\"', 'Mr', '.', 'Rickham', 'wanted', 'to', 'see', 'it', ',', '\"', 'she', 'began', ',', 'as', 'if', 'excusing', 'herself', '.', 'He', 'shrugged', 'his', 'shoulders', ',', 'still', 'smiling', '.', '\"', 'Oh', ',', 'Rickham', 'found', 'me', 'out', 'long', 'ago', ',', '\"', 'he', 'said', 'lightly', ';', 'then', ',', 'passing', 'his', 'arm', 'through', 'mine', ':', '\"', 'Come', 'and', 'see', 'the', 'rest', 'of', 'the', 'house', '.', '\"', 'He', 'showed', 'it', 'to', 'me', 'with', 'a', 'kind', 'of', 'naive', 'suburban', 'pride', ':', 'the', 'bath-rooms', ',', 'the', 'speaking-tubes', ',', 'the', 'dress-closets', ',', 'the', 'trouser-presses', '--', 'all', 'the', 'complex', 'simplifications', 'of', 'the', 'millionaire', \"'\", 's', 'domestic', 'economy', '.', 'And', 'whenever', 'my', 'wonder', 'paid', 'the', 'expected', 'tribute', 'he', 'said', ',', 'throwing', 'out', 'his', 'chest', 'a', 'little', ':', '\"', 'Yes', ',', 'I', 'really', 'don', \"'\", 't', 'see', 'how', 'people', 'manage', 'to', 'live', 'without', 'that', '.', '\"', 'Well', '--', 'it', 'was', 'just', 'the', 'end', 'one', 'might', 'have', 'foreseen', 'for', 'him', '.', 'Only', 'he', 'was', ',', 'through', 'it', 'all', 'and', 'in', 'spite', 'of', 'it', 'all', '--', 'as', 'he', 'had', 'been', 'through', ',', 'and', 'in', 'spite', 'of', ',', 'his', 'pictures', '--', 'so', 'handsome', ',', 'so', 'charming', ',', 'so', 'disarming', ',', 'that', 'one', 'longed', 'to', 'cry', 'out', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'leisure', '!', '\"', 'as', 'once', 'one', 'had', 'longed', 'to', 'say', ':', '\"', 'Be', 'dissatisfied', 'with', 'your', 'work', '!', '\"', 'But', ',', 'with', 'the', 'cry', 'on', 'my', 'lips', ',', 'my', 'diagnosis', 'suffered', 'an', 'unexpected', 'check', '.', '\"', 'This', 'is', 'my', 'own', 'lair', ',', '\"', 'he', 'said', ',', 'leading', 'me', 'into', 'a', 'dark', 'plain', 'room', 'at', 'the', 'end', 'of', 'the', 'florid', 'vista', '.', 'It', 'was', 'square', 'and', 'brown', 'and', 'leathery', ':', 'no', '\"', 'effects', '\"', ';', 'no', 'bric-a-brac', ',', 'none', 'of', 'the', 'air', 'of', 'posing', 'for', 'reproduction', 'in', 'a', 'picture', 'weekly', '--', 'above', 'all', ',', 'no', 'least', 'sign', 'of', 'ever', 'having', 'been', 'used', 'as', 'a', 'studio', '.', 'The', 'fact', 'brought', 'home', 'to', 'me', 'the', 'absolute', 'finality', 'of', 'Jack', \"'\", 's', 'break', 'with', 'his', 'old', 'life', '.', '\"', 'Don', \"'\", 't', 'you', 'ever', 'dabble', 'with', 'paint', 'any', 'more', '?', '\"', 'I', 'asked', ',', 'still', 'looking', 'about', 'for', 'a', 'trace', 'of', 'such', 'activity', '.', '\"', 'Never', ',', '\"', 'he', 'said', 'briefly', '.', '\"', 'Or', 'water-colour', '--', 'or', 'etching', '?', '\"', 'His', 'confident', 'eyes', 'grew', 'dim', ',', 'and', 'his', 'cheeks', 'paled', 'a', 'little', 'under', 'their', 'handsome', 'sunburn', '.', '\"', 'Never', 'think', 'of', 'it', ',', 'my', 'dear', 'fellow', '--', 'any', 'more', 'than', 'if', 'I', \"'\", 'd', 'never', 'touched', 'a', 'brush', '.', '\"', 'And', 'his', 'tone', 'told', 'me', 'in', 'a', 'flash', 'that', 'he', 'never', 'thought', 'of', 'anything', 'else', '.', 'I', 'moved', 'away', ',', 'instinctively', 'embarrassed', 'by', 'my', 'unexpected', 'discovery', ';', 'and', 'as', 'I', 'turned', ',', 'my', 'eye', 'fell', 'on', 'a', 'small', 'picture', 'above', 'the', 'mantel-piece', '--', 'the', 'only', 'object', 'breaking', 'the', 'plain', 'oak', 'panelling', 'of', 'the', 'room', '.', '\"', 'Oh', ',', 'by', 'Jove', '!', '\"', 'I', 'said', '.', 'It', 'was', 'a', 'sketch', 'of', 'a', 'donkey', '--', 'an', 'old', 'tired', 'donkey', ',', 'standing', 'in', 'the', 'rain', 'under', 'a', 'wall', '.', '\"', 'By', 'Jove', '--', 'a', 'Stroud', '!', '\"', 'I', 'cried', '.', 'He', 'was', 'silent', ';', 'but', 'I', 'felt', 'him', 'close', 'behind', 'me', ',', 'breathing', 'a', 'little', 'quickly', '.', '\"', 'What', 'a', 'wonder', '!', 'Made', 'with', 'a', 'dozen', 'lines', '--', 'but', 'on', 'everlasting', 'foundations', '.', 'You', 'lucky', 'chap', ',', 'where', 'did', 'you', 'get', 'it', '?', '\"', 'He', 'answered', 'slowly', ':', '\"', 'Mrs', '.', 'Stroud', 'gave', 'it', 'to', 'me', '.', '\"', '\"', 'Ah', '--', 'I', 'didn', \"'\", 't', 'know', 'you', 'even', 'knew', 'the', 'Strouds', '.', 'He', 'was', 'such', 'an', 'inflexible', 'hermit', '.', '\"', '\"', 'I', 'didn', \"'\", 't', '--', 'till', 'after', '.', '.', '.', '.', 'She', 'sent', 'for', 'me', 'to', 'paint', 'him', 'when', 'he', 'was', 'dead', '.', '\"', '\"', 'When', 'he', 'was', 'dead', '?', 'You', '?', '\"', 'I', 'must', 'have', 'let', 'a', 'little', 'too', 'much', 'amazement', 'escape', 'through', 'my', 'surprise', ',', 'for', 'he', 'answered', 'with', 'a', 'deprecating', 'laugh', ':', '\"', 'Yes', '--', 'she', \"'\", 's', 'an', 'awful', 'simpleton', ',', 'you', 'know', ',', 'Mrs', '.', 'Stroud', '.', 'Her', 'only', 'idea', 'was', 'to', 'have', 'him', 'done', 'by', 'a', 'fashionable', 'painter', '--', 'ah', ',', 'poor', 'Stroud', '!', 'She', 'thought', 'it', 'the', 'surest', 'way', 'of', 'proclaiming', 'his', 'greatness', '--', 'of', 'forcing', 'it', 'on', 'a', 'purblind', 'public', '.', 'And', 'at', 'the', 'moment', 'I', 'was', '_', 'the', '_', 'fashionable', 'painter', '.', '\"', '\"', 'Ah', ',', 'poor', 'Stroud', '--', 'as', 'you', 'say', '.', 'Was', '_', 'that', '_', 'his', 'history', '?', '\"', '\"', 'That', 'was', 'his', 'history', '.', 'She', 'believed', 'in', 'him', ',', 'gloried', 'in', 'him', '--', 'or', 'thought', 'she', 'did', '.', 'But', 'she', 'couldn', \"'\", 't', 'bear', 'not', 'to', 'have', 'all', 'the', 'drawing-rooms', 'with', 'her', '.', 'She', 'couldn', \"'\", 't', 'bear', 'the', 'fact', 'that', ',', 'on', 'varnishing', 'days', ',', 'one', 'could', 'always', 'get', 'near', 'enough', 'to', 'see', 'his', 'pictures', '.', 'Poor', 'woman', '!', 'She', \"'\", 's', 'just', 'a', 'fragment', 'groping', 'for', 'other', 'fragments', '.', 'Stroud', 'is', 'the', 'only', 'whole', 'I', 'ever', 'knew', '.', '\"', '\"', 'You', 'ever', 'knew', '?', 'But', 'you', 'just', 'said', '--', '\"', 'Gisburn', 'had', 'a', 'curious', 'smile', 'in', 'his', 'eyes', '.', '\"', 'Oh', ',', 'I', 'knew', 'him', ',', 'and', 'he', 'knew', 'me', '--', 'only', 'it', 'happened', 'after', 'he', 'was', 'dead', '.', '\"', 'I', 'dropped', 'my', 'voice', 'instinctively', '.', '\"', 'When', 'she', 'sent', 'for', 'you', '?', '\"', '\"', 'Yes', '--', 'quite', 'insensible', 'to', 'the', 'irony', '.', 'She', 'wanted', 'him', 'vindicated', '--', 'and', 'by', 'me', '!', '\"', 'He', 'laughed', 'again', ',', 'and', 'threw', 'back', 'his', 'head', 'to', 'look', 'up', 'at', 'the', 'sketch', 'of', 'the', 'donkey', '.', '\"', 'There', 'were', 'days', 'when', 'I', 'couldn', \"'\", 't', 'look', 'at', 'that', 'thing', '--', 'couldn', \"'\", 't', 'face', 'it', '.', 'But', 'I', 'forced', 'myself', 'to', 'put', 'it', 'here', ';', 'and', 'now', 'it', \"'\", 's', 'cured', 'me', '--', 'cured', 'me', '.', 'That', \"'\", 's', 'the', 'reason', 'why', 'I', 'don', \"'\", 't', 'dabble', 'any', 'more', ',', 'my', 'dear', 'Rickham', ';', 'or', 'rather', 'Stroud', 'himself', 'is', 'the', 'reason', '.', '\"', 'For', 'the', 'first', 'time', 'my', 'idle', 'curiosity', 'about', 'my', 'companion', 'turned', 'into', 'a', 'serious', 'desire', 'to', 'understand', 'him', 'better', '.', '\"', 'I', 'wish', 'you', \"'\", 'd', 'tell', 'me', 'how', 'it', 'happened', ',', '\"', 'I', 'said', '.', 'He', 'stood', 'looking', 'up', 'at', 'the', 'sketch', ',', 'and', 'twirling', 'between', 'his', 'fingers', 'a', 'cigarette', 'he', 'had', 'forgotten', 'to', 'light', '.', 'Suddenly', 'he', 'turned', 'toward', 'me', '.', '\"', 'I', \"'\", 'd', 'rather', 'like', 'to', 'tell', 'you', '--', 'because', 'I', \"'\", 've', 'always', 'suspected', 'you', 'of', 'loathing', 'my', 'work', '.', '\"', 'I', 'made', 'a', 'deprecating', 'gesture', ',', 'which', 'he', 'negatived', 'with', 'a', 'good-humoured', 'shrug', '.', '\"', 'Oh', ',', 'I', 'didn', \"'\", 't', 'care', 'a', 'straw', 'when', 'I', 'believed', 'in', 'myself', '--', 'and', 'now', 'it', \"'\", 's', 'an', 'added', 'tie', 'between', 'us', '!', '\"', 'He', 'laughed', 'slightly', ',', 'without', 'bitterness', ',', 'and', 'pushed', 'one', 'of', 'the', 'deep', 'arm-chairs', 'forward', '.', '\"', 'There', ':', 'make', 'yourself', 'comfortable', '--', 'and', 'here', 'are', 'the', 'cigars', 'you', 'like', '.', '\"', 'He', 'placed', 'them', 'at', 'my', 'elbow', 'and', 'continued', 'to', 'wander', 'up', 'and', 'down', 'the', 'room', ',', 'stopping', 'now', 'and', 'then', 'beneath', 'the', 'picture', '.', '\"', 'How', 'it', 'happened', '?', 'I', 'can', 'tell', 'you', 'in', 'five', 'minutes', '--', 'and', 'it', 'didn', \"'\", 't', 'take', 'much', 'longer', 'to', 'happen', '.', '.', '.', '.', 'I', 'can', 'remember', 'now', 'how', 'surprised', 'and', 'pleased', 'I', 'was', 'when', 'I', 'got', 'Mrs', '.', 'Stroud', \"'\", 's', 'note', '.', 'Of', 'course', ',', 'deep', 'down', ',', 'I', 'had', 'always', '_', 'felt', '_', 'there', 'was', 'no', 'one', 'like', 'him', '--', 'only', 'I', 'had', 'gone', 'with', 'the', 'stream', ',', 'echoed', 'the', 'usual', 'platitudes', 'about', 'him', ',', 'till', 'I', 'half', 'got', 'to', 'think', 'he', 'was', 'a', 'failure', ',', 'one', 'of', 'the', 'kind', 'that', 'are', 'left', 'behind', '.', 'By', 'Jove', ',', 'and', 'he', '_', 'was', '_', 'left', 'behind', '--', 'because', 'he', 'had', 'come', 'to', 'stay', '!', 'The', 'rest', 'of', 'us', 'had', 'to', 'let', 'ourselves', 'be', 'swept', 'along', 'or', 'go', 'under', ',', 'but', 'he', 'was', 'high', 'above', 'the', 'current', '--', 'on', 'everlasting', 'foundations', ',', 'as', 'you', 'say', '.', '\"', 'Well', ',', 'I', 'went', 'off', 'to', 'the', 'house', 'in', 'my', 'most', 'egregious', 'mood', '--', 'rather', 'moved', ',', 'Lord', 'forgive', 'me', ',', 'at', 'the', 'pathos', 'of', 'poor', 'Stroud', \"'\", 's', 'career', 'of', 'failure', 'being', 'crowned', 'by', 'the', 'glory', 'of', 'my', 'painting', 'him', '!', 'Of', 'course', 'I', 'meant', 'to', 'do', 'the', 'picture', 'for', 'nothing', '--', 'I', 'told', 'Mrs', '.', 'Stroud', 'so', 'when', 'she', 'began', 'to', 'stammer', 'something', 'about', 'her', 'poverty', '.', 'I', 'remember', 'getting', 'off', 'a', 'prodigious', 'phrase', 'about', 'the', 'honour', 'being', '_', 'mine', '_', '--', 'oh', ',', 'I', 'was', 'princely', ',', 'my', 'dear', 'Rickham', '!', 'I', 'was', 'posing', 'to', 'myself', 'like', 'one', 'of', 'my', 'own', 'sitters', '.', '\"', 'Then', 'I', 'was', 'taken', 'up', 'and', 'left', 'alone', 'with', 'him', '.', 'I', 'had', 'sent', 'all', 'my', 'traps', 'in', 'advance', ',', 'and', 'I', 'had', 'only', 'to', 'set', 'up', 'the', 'easel', 'and', 'get', 'to', 'work', '.', 'He', 'had', 'been', 'dead', 'only', 'twenty-four', 'hours', ',', 'and', 'he', 'died', 'suddenly', ',', 'of', 'heart', 'disease', ',', 'so', 'that', 'there', 'had', 'been', 'no', 'preliminary', 'work', 'of', 'destruction', '--', 'his', 'face', 'was', 'clear', 'and', 'untouched', '.', 'I', 'had', 'met', 'him', 'once', 'or', 'twice', ',', 'years', 'before', ',', 'and', 'thought', 'him', 'insignificant', 'and', 'dingy', '.', 'Now', 'I', 'saw', 'that', 'he', 'was', 'superb', '.', '\"', 'I', 'was', 'glad', 'at', 'first', ',', 'with', 'a', 'merely', 'aesthetic', 'satisfaction', ':', 'glad', 'to', 'have', 'my', 'hand', 'on', 'such', 'a', \"'\", 'subject', '.', \"'\", 'Then', 'his', 'strange', 'life-likeness', 'began', 'to', 'affect', 'me', 'queerly', '--', 'as', 'I', 'blocked', 'the', 'head', 'in', 'I', 'felt', 'as', 'if', 'he', 'were', 'watching', 'me', 'do', 'it', '.', 'The', 'sensation', 'was', 'followed', 'by', 'the', 'thought', ':', 'if', 'he', '_', 'were', '_', 'watching', 'me', ',', 'what', 'would', 'he', 'say', 'to', 'my', 'way', 'of', 'working', '?', 'My', 'strokes', 'began', 'to', 'go', 'a', 'little', 'wild', '--', 'I', 'felt', 'nervous', 'and', 'uncertain', '.', '\"', 'Once', ',', 'when', 'I', 'looked', 'up', ',', 'I', 'seemed', 'to', 'see', 'a', 'smile', 'behind', 'his', 'close', 'grayish', 'beard', '--', 'as', 'if', 'he', 'had', 'the', 'secret', ',', 'and', 'were', 'amusing', 'himself', 'by', 'holding', 'it', 'back', 'from', 'me', '.', 'That', 'exasperated', 'me', 'still', 'more', '.', 'The', 'secret', '?', 'Why', ',', 'I', 'had', 'a', 'secret', 'worth', 'twenty', 'of', 'his', '!', 'I', 'dashed', 'at', 'the', 'canvas', 'furiously', ',', 'and', 'tried', 'some', 'of', 'my', 'bravura', 'tricks', '.', 'But', 'they', 'failed', 'me', ',', 'they', 'crumbled', '.', 'I', 'saw', 'that', 'he', 'wasn', \"'\", 't', 'watching', 'the', 'showy', 'bits', '--', 'I', 'couldn', \"'\", 't', 'distract', 'his', 'attention', ';', 'he', 'just', 'kept', 'his', 'eyes', 'on', 'the', 'hard', 'passages', 'between', '.', 'Those', 'were', 'the', 'ones', 'I', 'had', 'always', 'shirked', ',', 'or', 'covered', 'up', 'with', 'some', 'lying', 'paint', '.', 'And', 'how', 'he', 'saw', 'through', 'my', 'lies', '!', '\"', 'I', 'looked', 'up', 'again', ',', 'and', 'caught', 'sight', 'of', 'that', 'sketch', 'of', 'the', 'donkey', 'hanging', 'on', 'the', 'wall', 'near', 'his', 'bed', '.', 'His', 'wife', 'told', 'me', 'afterward', 'it', 'was', 'the', 'last', 'thing', 'he', 'had', 'done', '--', 'just', 'a', 'note', 'taken', 'with', 'a', 'shaking', 'hand', ',', 'when', 'he', 'was', 'down', 'in', 'Devonshire', 'recovering', 'from', 'a', 'previous', 'heart', 'attack', '.', 'Just', 'a', 'note', '!', 'But', 'it', 'tells', 'his', 'whole', 'history', '.', 'There', 'are', 'years', 'of', 'patient', 'scornful', 'persistence', 'in', 'every', 'line', '.', 'A', 'man', 'who', 'had', 'swum', 'with', 'the', 'current', 'could', 'never', 'have', 'learned', 'that', 'mighty', 'up-stream', 'stroke', '.', '.', '.', '.', '\"', 'I', 'turned', 'back', 'to', 'my', 'work', ',', 'and', 'went', 'on', 'groping', 'and', 'muddling', ';', 'then', 'I', 'looked', 'at', 'the', 'donkey', 'again', '.', 'I', 'saw', 'that', ',', 'when', 'Stroud', 'laid', 'in', 'the', 'first', 'stroke', ',', 'he', 'knew', 'just', 'what', 'the', 'end', 'would', 'be', '.', 'He', 'had', 'possessed', 'his', 'subject', ',', 'absorbed', 'it', ',', 'recreated', 'it', '.', 'When', 'had', 'I', 'done', 'that', 'with', 'any', 'of', 'my', 'things', '?', 'They', 'hadn', \"'\", 't', 'been', 'born', 'of', 'me', '--', 'I', 'had', 'just', 'adopted', 'them', '.', '.', '.', '.', '\"', 'Hang', 'it', ',', 'Rickham', ',', 'with', 'that', 'face', 'watching', 'me', 'I', 'couldn', \"'\", 't', 'do', 'another', 'stroke', '.', 'The', 'plain', 'truth', 'was', ',', 'I', 'didn', \"'\", 't', 'know', 'where', 'to', 'put', 'it', '--', '_', 'I', 'had', 'never', 'known', '_', '.', 'Only', ',', 'with', 'my', 'sitters', 'and', 'my', 'public', ',', 'a', 'showy', 'splash', 'of', 'colour', 'covered', 'up', 'the', 'fact', '--', 'I', 'just', 'threw', 'paint', 'into', 'their', 'faces', '.', '.', '.', '.', 'Well', ',', 'paint', 'was', 'the', 'one', 'medium', 'those', 'dead', 'eyes', 'could', 'see', 'through', '--', 'see', 'straight', 'to', 'the', 'tottering', 'foundations', 'underneath', '.', 'Don', \"'\", 't', 'you', 'know', 'how', ',', 'in', 'talking', 'a', 'foreign', 'language', ',', 'even', 'fluently', ',', 'one', 'says', 'half', 'the', 'time', 'not', 'what', 'one', 'wants', 'to', 'but', 'what', 'one', 'can', '?', 'Well', '--', 'that', 'was', 'the', 'way', 'I', 'painted', ';', 'and', 'as', 'he', 'lay', 'there', 'and', 'watched', 'me', ',', 'the', 'thing', 'they', 'called', 'my', \"'\", 'technique', \"'\", 'collapsed', 'like', 'a', 'house', 'of', 'cards', '.', 'He', 'didn', \"'\", 't', 'sneer', ',', 'you', 'understand', ',', 'poor', 'Stroud', '--', 'he', 'just', 'lay', 'there', 'quietly', 'watching', ',', 'and', 'on', 'his', 'lips', ',', 'through', 'the', 'gray', 'beard', ',', 'I', 'seemed', 'to', 'hear', 'the', 'question', ':', \"'\", 'Are', 'you', 'sure', 'you', 'know', 'where', 'you', \"'\", 're', 'coming', 'out', '?', \"'\", '\"', 'If', 'I', 'could', 'have', 'painted', 'that', 'face', ',', 'with', 'that', 'question', 'on', 'it', ',', 'I', 'should', 'have', 'done', 'a', 'great', 'thing', '.', 'The', 'next', 'greatest', 'thing', 'was', 'to', 'see', 'that', 'I', 'couldn', \"'\", 't', '--', 'and', 'that', 'grace', 'was', 'given', 'me', '.', 'But', ',', 'oh', ',', 'at', 'that', 'minute', ',', 'Rickham', ',', 'was', 'there', 'anything', 'on', 'earth', 'I', 'wouldn', \"'\", 't', 'have', 'given', 'to', 'have', 'Stroud', 'alive', 'before', 'me', ',', 'and', 'to', 'hear', 'him', 'say', ':', \"'\", 'It', \"'\", 's', 'not', 'too', 'late', '--', 'I', \"'\", 'll', 'show', 'you', 'how', \"'\", '?', '\"', 'It', '_', 'was', '_', 'too', 'late', '--', 'it', 'would', 'have', 'been', ',', 'even', 'if', 'he', \"'\", 'd', 'been', 'alive', '.', 'I', 'packed', 'up', 'my', 'traps', ',', 'and', 'went', 'down', 'and', 'told', 'Mrs', '.', 'Stroud', '.', 'Of', 'course', 'I', 'didn', \"'\", 't', 'tell', 'her', '_', 'that', '_', '--', 'it', 'would', 'have', 'been', 'Greek', 'to', 'her', '.', 'I', 'simply', 'said', 'I', 'couldn', \"'\", 't', 'paint', 'him', ',', 'that', 'I', 'was', 'too', 'moved', '.', 'She', 'rather', 'liked', 'the', 'idea', '--', 'she', \"'\", 's', 'so', 'romantic', '!', 'It', 'was', 'that', 'that', 'made', 'her', 'give', 'me', 'the', 'donkey', '.', 'But', 'she', 'was', 'terribly', 'upset', 'at', 'not', 'getting', 'the', 'portrait', '--', 'she', 'did', 'so', 'want', 'him', \"'\", 'done', \"'\", 'by', 'some', 'one', 'showy', '!', 'At', 'first', 'I', 'was', 'afraid', 'she', 'wouldn', \"'\", 't', 'let', 'me', 'off', '--', 'and', 'at', 'my', 'wits', \"'\", 'end', 'I', 'suggested', 'Grindle', '.', 'Yes', ',', 'it', 'was', 'I', 'who', 'started', 'Grindle', ':', 'I', 'told', 'Mrs', '.', 'Stroud', 'he', 'was', 'the', \"'\", 'coming', \"'\", 'man', ',', 'and', 'she', 'told', 'somebody', 'else', ',', 'and', 'so', 'it', 'got', 'to', 'be', 'true', '.', '.', '.', '.', 'And', 'he', 'painted', 'Stroud', 'without', 'wincing', ';', 'and', 'she', 'hung', 'the', 'picture', 'among', 'her', 'husband', \"'\", 's', 'things', '.', '.', '.', '.', '\"', 'He', 'flung', 'himself', 'down', 'in', 'the', 'arm-chair', 'near', 'mine', ',', 'laid', 'back', 'his', 'head', ',', 'and', 'clasping', 'his', 'arms', 'beneath', 'it', ',', 'looked', 'up', 'at', 'the', 'picture', 'above', 'the', 'chimney-piece', '.', '\"', 'I', 'like', 'to', 'fancy', 'that', 'Stroud', 'himself', 'would', 'have', 'given', 'it', 'to', 'me', ',', 'if', 'he', \"'\", 'd', 'been', 'able', 'to', 'say', 'what', 'he', 'thought', 'that', 'day', '.', '\"', 'And', ',', 'in', 'answer', 'to', 'a', 'question', 'I', 'put', 'half-mechanically', '--', '\"', 'Begin', 'again', '?', '\"', 'he', 'flashed', 'out', '.', '\"', 'When', 'the', 'one', 'thing', 'that', 'brings', 'me', 'anywhere', 'near', 'him', 'is', 'that', 'I', 'knew', 'enough', 'to', 'leave', 'off', '?', '\"', 'He', 'stood', 'up', 'and', 'laid', 'his', 'hand', 'on', 'my', 'shoulder', 'with', 'a', 'laugh', '.', '\"', 'Only', 'the', 'irony', 'of', 'it', 'is', 'that', 'I', '_', 'am', '_', 'still', 'painting', '--', 'since', 'Grindle', \"'\", 's', 'doing', 'it', 'for', 'me', '!', 'The', 'Strouds', 'stand', 'alone', ',', 'and', 'happen', 'once', '--', 'but', 'there', \"'\", 's', 'no', 'exterminating', 'our', 'kind', 'of', 'art', '.', '\"']\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccb88c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words  = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd9c30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c765238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "  print(item)\n",
    "  if i >= 50:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "439640f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleTokenizerV1:\n",
    "#   def __init__(self, vocab: dict[str, int]):\n",
    "#     self.str_to_int = vocab\n",
    "#     self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "#   def encode(self, text: str):\n",
    "#     preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "\n",
    "#     preprocessed = [\n",
    "#       item.strip() for item in preprocessed if item.strip()\n",
    "#     ]\n",
    "#     ids = [self.str_to_int[s] for s in preprocessed]\n",
    "#     return ids\n",
    "  \n",
    "#   def decode(self, ids: list[int]):\n",
    "#     text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "#     text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "#     return text\n",
    "  \n",
    "class SimpleTokenizerV1():\n",
    "  def __init__(self, vocab: dict[str, int]):\n",
    "    self.str_to_int = vocab\n",
    "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "  def encode(self, text: str):\n",
    "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "    ids = [self.str_to_int[s] for s in preprocessed]\n",
    "    return ids\n",
    "\n",
    "  def decode(self, ids: list[int]):\n",
    "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "    text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3063edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 115, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "# text = \"\"\"\"It's the last he painted, you know,\"\n",
    "#           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "# ids = tokenizer.encode(text)\n",
    "# print(ids)\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "          Mrs. Gisburn said with a pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e828f8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with a pardonable pride.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f6bb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tokens = sorted(list(set(preprocessed)))\n",
    "# all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "# vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9678be89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49cf1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "204e91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleTokenizerV2:\n",
    "#   def __init__(self, vocab: dict[str, int]):\n",
    "#     self.str_to_int = vocab\n",
    "#     self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "#   def encode(self, text: str):\n",
    "#     preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "#     preprocessed = [\n",
    "#       item.strip() for item in preprocessed if item.strip()\n",
    "#     ]\n",
    "#     preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "    \n",
    "#     ids = [self.str_to_int[s] for s in preprocessed]\n",
    "#     return ids\n",
    "  \n",
    "#   def decode(self, ids: list[int]):\n",
    "#     text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "#     text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "#     return text\n",
    "\n",
    "class SimpleTokenizerV2():\n",
    "  def __init__(self, vocab: dict[str, int]):\n",
    "    self.str_to_int = vocab\n",
    "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "  def encode(self, text: str):\n",
    "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "    preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "\n",
    "    ids = [self.str_to_int[s] for s in preprocessed]\n",
    "    return ids\n",
    "\n",
    "  def decode(self, ids: list[int]):\n",
    "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "    text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3dff311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0553e0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48603750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "091a9b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for tiktoken",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:397\u001b[39m, in \u001b[36mDistribution.from_name\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiscover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[31mStopIteration\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPackageNotFoundError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtiktoken\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mtiktoken version\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtiktoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:888\u001b[39m, in \u001b[36mversion\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mversion\u001b[39m(distribution_name):\n\u001b[32m    882\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[32m    883\u001b[39m \n\u001b[32m    884\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[32m    885\u001b[39m \u001b[33;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[32m    886\u001b[39m \u001b[33;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[32m    887\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m.version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:861\u001b[39m, in \u001b[36mdistribution\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdistribution\u001b[39m(distribution_name):\n\u001b[32m    856\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[32m    857\u001b[39m \n\u001b[32m    858\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[32m    859\u001b[39m \u001b[33;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[32m    860\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:399\u001b[39m, in \u001b[36mDistribution.from_name\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m.discover(name=name))\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[31mPackageNotFoundError\u001b[39m: No package metadata was found for tiktoken"
     ]
    }
   ],
   "source": [
    "# import importlib.metadata\n",
    "# import tiktoken\n",
    "\n",
    "# print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
    "\n",
    "import importlib.metadata\n",
    "import tiktoken\n",
    "\n",
    "print (\"tiktoken version\", importlib.metadata.version(\"tiktoken\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "777ecdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4ef071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = (\n",
    "#   \"Hello do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "#     \"of someunknownPlace\"\n",
    "# )\n",
    "\n",
    "# integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "text = (\n",
    "  \"Hello do you like tea? <|endoftext|> In the sunlit terraces\" \"of someunknownPlace\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a18df7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35409ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "\n",
    "print(enc_text[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3fe809a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49603c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:       [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:       {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71c63fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "  context = enc_sample[:i]\n",
    "  desired = enc_sample[i]\n",
    "\n",
    "  print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2830d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "  context = enc_sample[:i]\n",
    "  desired = enc_sample[i]\n",
    "\n",
    "  print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe8a58e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_Number' from 'torch.types' (c:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\__init__.py:2169\u001b[39m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2160\u001b[39m \n\u001b[32m   2161\u001b[39m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[32m   2162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2163\u001b[39m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[32m   2164\u001b[39m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[32m   2165\u001b[39m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[32m   2166\u001b[39m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[32m   2167\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2169\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m   2170\u001b[39m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[32m   2171\u001b[39m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[32m   2172\u001b[39m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[32m   2173\u001b[39m     accelerator \u001b[38;5;28;01mas\u001b[39;00m accelerator,\n\u001b[32m   2174\u001b[39m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[32m   2175\u001b[39m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[32m   2176\u001b[39m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[32m   2177\u001b[39m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[32m   2178\u001b[39m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[32m   2179\u001b[39m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[32m   2180\u001b[39m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[32m   2181\u001b[39m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[32m   2182\u001b[39m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[32m   2183\u001b[39m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[32m   2184\u001b[39m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[32m   2185\u001b[39m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[32m   2186\u001b[39m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[32m   2187\u001b[39m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[32m   2188\u001b[39m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[32m   2189\u001b[39m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[32m   2190\u001b[39m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[32m   2191\u001b[39m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[32m   2192\u001b[39m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[32m   2193\u001b[39m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[32m   2194\u001b[39m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[32m   2195\u001b[39m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[32m   2196\u001b[39m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[32m   2197\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m   2198\u001b[39m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[32m   2199\u001b[39m )\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[32m   2203\u001b[39m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[32m   2204\u001b[39m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\__init__.py:74\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe ``distributions`` package contains parameterizable probability distributions\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mand sampling functions. This allows the construction of stochastic computation\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     71\u001b[39m \u001b[33;03m    loss.backward()\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbernoulli\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bernoulli\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbeta\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Beta\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\transforms.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constraints\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _sum_rightmost,\n\u001b[32m     13\u001b[39m     broadcast_all,\n\u001b[32m     14\u001b[39m     lazy_property,\n\u001b[32m     15\u001b[39m     tril_matrix_to_vec,\n\u001b[32m     16\u001b[39m     vec_to_tril_matrix,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad, softplus\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Number\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\distributions\\utils.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_tensor_like\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Number\n\u001b[32m     13\u001b[39m euler_constant = \u001b[32m0.57721566490153286060\u001b[39m  \u001b[38;5;66;03m# Euler Mascheroni Constant\u001b[39;00m\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbroadcast_all\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlogits_to_probs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvec_to_tril_matrix\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m ]\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '_Number' from 'torch.types' (c:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\types.py)"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e2fdf9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset and DataLoader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mGPTDatasetV1\u001b[39;00m(Dataset): \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OpeyemiAkande\\Desktop\\practice\\python\\pytorch\\torchenv\\Lib\\site-packages\\torch\\__init__.py:764\u001b[39m\n\u001b[32m    761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[32m    763\u001b[39m __name, __obj = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m __name[\u001b[32m0\u001b[39m] != \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __name.endswith(\u001b[33m'\u001b[39m\u001b[33mBase\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    766\u001b[39m         __all__.append(__name)\n",
      "\u001b[31mNameError\u001b[39m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset and DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Any\n",
    "\n",
    "class GPTDatasetV1(Dataset): # type: ignore\n",
    "  def __init__(self, txt: str, tokenizer: Any, max_length: int, stride: int):\n",
    "    self.input_ids: list[int] = []\n",
    "    self.target_ids: list[int] = []\n",
    "\n",
    "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "    assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "    for i in range(0, len(token_ids) - max_length, stride):\n",
    "      input_chunk = token_ids[i:i + max_length]\n",
    "      target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "      self.input_ids.append(torch.tensor(input_chunk))  # type: ignore\n",
    "      self.target_ids.append(torch.tensor(target_chunk))# type: ignore\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  \n",
    "  def __getitem__(self, idx: int):\n",
    "    return self.input_ids[idx],self.target_ids[idx]\n",
    "  \n",
    "\n",
    "def create_dataloader_v1(txt: str, batch_size: int = 4, \n",
    "                         max_length: int = 256, stride: int=128,\n",
    "                        shuffle: bool=True, drop_last: bool = True,\n",
    "                        num_workers: int=0):\n",
    "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,  # type: ignore\n",
    "                          drop_last=drop_last, num_workers=num_workers)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6002b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  raw_text = f.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
